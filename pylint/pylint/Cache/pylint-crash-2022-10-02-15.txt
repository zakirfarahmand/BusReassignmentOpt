First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
from math import comb
import statistics
import datetime as dt
from datetime import datetime, timedelta

from traceback import format_exception
from unittest.util import sorted_list_difference
from webbrowser import get
from click import secho
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from gurobipy import tuplelist
import googlemaps
from soupsieve import select
import pyodbc
from matplotlib import style
plt.style.use('seaborn-dark')

# Requires API key
gmaps = googlemaps.Client(key='AIzaSyAUksLuaZra4mCcOLZL_52b9nIvHa7TgFw')
# gmaps = googlemaps.Client(key='AIzaSyAra0o3L3rs-uHn4EpaXx1Y57SIF_02684')


def connect_to_database():
    conn = pyodbc.connect('Driver={SQL Server Native Client 11.0};'
                          'Server=UT163156;'
                          'Database=keolis;'
                          'Trusted_Connection=yes;')
    cursor = conn.cursor()
    return cursor, conn




def import_data(date):
    # call data from the database
    cursor, conn = connect_to_database()
    data = pd.read_sql_query(
        "select * from pred_occupancy_per_stop where operating_date = '{}' ".format(date), conn)
    cursor.close()

    data['departure_time'] = pd.to_datetime(
        data['departure_time'], format='%Y-%m-%d %H:%M:%S')
    data['passing_time'] = pd.to_datetime(
        data['passing_time'], format='%Y-%m-%d %H:%M:%S')

    data.sort_values(by=['dep_time', 'system_linenr',
                     'direction', 'trip_number'], inplace=True)
    return data


def preliminary_parameters(date):
    cursor, conn = connect_to_database()
    data = pd.read_sql(
        "SELECT * FROM trips_timetable WHERE operating_date = '{}'".format(date), conn)
    cursor.close()

    first_stop_dict = {}
    last_stop_dict = {}
    bus_trips_dict = {}
    line_trips_dict = {}
    dep_time_dict = {}
    arr_time_dict = {}
    travel_time_dict = {}
    # convert time to seconds
    for i in range(len(data)):
        dep_time = data.loc[i, 'departure_time']
        data.loc[i, 'departure_time'] = dt.timedelta(
            hours=dep_time.hour, minutes=dep_time.minute, seconds=dep_time.second).total_seconds()
    for i in range(len(data)):
        arr_time = data.loc[i, 'arrival_time']
        data.loc[i, 'arrival_time'] = dt.timedelta(
            hours=arr_time.hour, minutes=arr_time.minute, seconds=arr_time.second).total_seconds()
    # create dictionary for the first stop of each trip
    first_stop_dict.update({k: v for k, v in zip(
        data['trip_number'], data['start_stop'])})
    # create dictionary for the last stop of each trip
    last_stop_dict.update({k: v for k, v in zip(
        data['trip_number'], data['last_stop'])})
    # create departure and arrival times dictionary
    dep_time_dict.update({i: j for i, j in zip(
        data['trip_number'], data['departure_time'])})
    arr_time_dict.update({i: j for i, j in zip(
        data['trip_number'], data['arrival_time'])})
    # calculate travel time for each trip
    for k1, v1 in dep_time_dict.items():
        for k2, v2 in arr_time_dict.items():
            if k1 == k2:
                travel_time = v2 - v1
                travel_time_dict.update({k1: travel_time})
    # list of trips on the same line
    line_trips_dict.update({k: list(v) for k, v in data.groupby(
        'system_linenr')['trip_number']})
    # list of trips operating by the same bus
    bus_trips_dict.update({k: list(v)
                           for k, v in data.groupby('vehicle_number')['trip_number']})

    # return datasets
    return first_stop_dict, last_stop_dict, dep_time_dict, arr_time_dict, travel_time_dict


def calculate_waiting_time(date):

    waiting_time_dict = {}

    cursor, conn = connect_to_database()
    data = pd.read_sql(
        "SELECT * FROM timetable WHERE operating_date = '{}'".format(date), conn)
    cursor.close()

    # convert time to seconds
    for i in range(len(data)):
        dep_time = data.loc[i, 'departure_time']
        data.loc[i, 'departure_time'] = dt.timedelta(
            hours=dep_time.hour, minutes=dep_time.minute, seconds=dep_time.second).total_seconds()
    for i in range(len(data)):
        pass_time = data.loc[i, 'passing_time']
        data.loc[i, 'passing_time'] = dt.timedelta(
            hours=pass_time.hour, minutes=pass_time.minute, seconds=pass_time.second).total_seconds()

    for i in range(len(data)):
        data.loc[i, 'hour'] = int(data.loc[i, 'passing_time']/3600)

    data = data.sort_values(by=['system_linenr', 'direction', 'passing_time'])

    # calculate headway for different time of the day: peak and off-peak
    data['headway'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'passing_time'].transform(pd.Series.diff)
    data.dropna(inplace=True)

    data['variance'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'headway'].transform(statistics.variance)
    data['mean'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'headway'].transform(statistics.mean)

    def cal_waiting_time(mean, var):
        waiting_time = mean * 0.5 + 0.5 * (var / mean)
        return waiting_time
    # calculate waiting time
    data['waiting_time'] = cal_waiting_time(
        data['mean'], data['variance'])

    waiting_time_dict.update({(i, j): k for i, j, k in zip(
        data['trip_number'], data['stop'], data['waiting_time'])})

    return waiting_time_dict


def calculate_distance(lat1, lon1, lat2, lon2):

    distance = gmaps.distance_matrix([str(lat1) + " " + str(lon1)],
                                     [str(lat2) + " " + str(lon2)],
                                     departure_time=datetime.now().timestamp(),
                                     mode='driving')["rows"][0]["elements"][0]["duration"]["value"]
    return distance


def calculate_deadhead(date):
    cursor, conn = connect_to_database()
    date= str(date)
    data = pd.read_sql(
        "SELECT * FROM timetable WHERE operating_date = '{}'".format(date), conn)
    data = data.replace({np.nan: None})

    for i in range(len(data)):
        if data.loc[i, 'passing_time'] is not None:
            data.loc[i, 'passing_time'] = data.loc[i, 'passing_time']
        else:
            data.loc[i, 'passing_time'] = data.loc[i, 'arrival_time']
    first_stop = data.sort_values(by=['trip_number', 'passing_time']).drop_duplicates(
        subset=['trip_number'], keep='first')

    # create dictionary for the last stop of each trip
    last_stop = data.sort_values(by=['trip_number', 'passing_time']).drop_duplicates(
        subset=['trip_number'], keep='last')

    stops = pd.read_csv(
        r'C:/Users/FARAHMANDZH/OneDrive - University of Twente/Documenten/PDEng Project/Data/bus_stops.csv', sep=';')
    cursor.close()

    first_stop = pd.merge(first_stop, stops, left_on=[
                          'stop'], right_on=['IdDimHalte'])
    last_stop = pd.merge(last_stop, stops, left_on=[
        'stop'], right_on=['IdDimHalte'])

    first_stop.drop_duplicates('stop', inplace=True, keep='first')

    last_stop.drop_duplicates('stop', inplace=True, keep='first')
    first_stop_dict = {}
    last_stop_dict = {}
    first_stop_dict.update({i: (j, v) for i, j, v in zip(
        first_stop['stop'],  first_stop['Breedtegraad'], first_stop['Lengtegraad'])})
    # create dictionary for the last stop of each trip
    last_stop_dict.update({i: (j, v) for i, j, v in zip(
        last_stop['stop'], last_stop['Breedtegraad'], last_stop['Lengtegraad'])})

    data = pd.DataFrame(columns=['stopA', 'stopB', 'deadhead'])
    for key1, val1 in first_stop_dict.items():
        for key2, val2 in first_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)
    for key1, val1 in first_stop_dict.items():
        for key2, val2 in last_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)
    for key1, val1 in last_stop_dict.items():
        for key2, val2 in first_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)

    data.drop_duplicates(subset=['stopA', 'stopB'], inplace=True, keep='first')
    # directly store the data to the databse
    data = data.values.tolist()
    cursor, conn = connect_to_database()
    sql_insert = '''
        declare @stopA bigint = ?
        declare @stopB bigint = ?
        declare @deadhead float = ?

        UPDATE deadhead_time    
        SET deadhead = @deadhead
        WHERE stopA = @stopA AND stopB = @stopB

        IF @@ROWCOUNT = 0
            INSERT INTO deadhead_time
                (stopA, stopB, deadhead)
            VALUES (@stopA, @stopB, @deadhead)
        '''
    cursor.executemany(sql_insert, data)

    conn.commit()

date = dt.datetime.today().date() + timedelta(days=1)
calculate_deadhead(date)

```

pylint crashed with a ``MemoryError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1111, in _check_files
    self._check_file(get_ast, check_astroid_module, file)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1146, in _check_file
    check_astroid_module(ast_node)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1298, in check_astroid_module
    retval = self._check_astroid_module(
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1345, in _check_astroid_module
    walker.walk(node)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 76, in walk
    self.walk(child)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 73, in walk
    callback(astroid)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\checkers\variables.py", line 1722, in visit_import
    module = next(_infer_name_module(node, parts[0]))
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 136, in raise_if_nothing_inferred
    yield next(generator)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\inference.py", line 266, in infer_import
    yield self.do_import_module(name)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\mixins.py", line 102, in do_import_module
    return mymodule.import_module(
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(absmodname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 189, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 102, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 104, in file_build
    stream, encoding, data = open_source_file(path)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 40, in open_source_file
    data = stream.read()
MemoryError
```
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
from math import comb
import statistics
import datetime as dt
from datetime import datetime, timedelta

from traceback import format_exception
from unittest.util import sorted_list_difference
from webbrowser import get
from click import secho
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from gurobipy import tuplelist
import googlemaps
from soupsieve import select
import pyodbc
from matplotlib import style
plt.style.use('seaborn-dark')

# Requires API key
gmaps = googlemaps.Client(key='AIzaSyAUksLuaZra4mCcOLZL_52b9nIvHa7TgFw')
# gmaps = googlemaps.Client(key='AIzaSyAra0o3L3rs-uHn4EpaXx1Y57SIF_02684')


def connect_to_database():
    conn = pyodbc.connect('Driver={SQL Server Native Client 11.0};'
                          'Server=UT163156;'
                          'Database=keolis;'
                          'Trusted_Connection=yes;')
    cursor = conn.cursor()
    return cursor, conn




def import_data(date):
    # call data from the database
    cursor, conn = connect_to_database()
    data = pd.read_sql_query(
        "select * from pred_occupancy_per_stop where operating_date = '{}' ".format(date), conn)
    cursor.close()

    data['departure_time'] = pd.to_datetime(
        data['departure_time'], format='%Y-%m-%d %H:%M:%S')
    data['passing_time'] = pd.to_datetime(
        data['passing_time'], format='%Y-%m-%d %H:%M:%S')

    data.sort_values(by=['dep_time', 'system_linenr',
                     'direction', 'trip_number'], inplace=True)
    return data


def preliminary_parameters(date):
    cursor, conn = connect_to_database()
    data = pd.read_sql(
        "SELECT * FROM trips_timetable WHERE operating_date = '{}'".format(date), conn)
    cursor.close()

    first_stop_dict = {}
    last_stop_dict = {}
    bus_trips_dict = {}
    line_trips_dict = {}
    dep_time_dict = {}
    arr_time_dict = {}
    travel_time_dict = {}
    # convert time to seconds
    for i in range(len(data)):
        dep_time = data.loc[i, 'departure_time']
        data.loc[i, 'departure_time'] = dt.timedelta(
            hours=dep_time.hour, minutes=dep_time.minute, seconds=dep_time.second).total_seconds()
    for i in range(len(data)):
        arr_time = data.loc[i, 'arrival_time']
        data.loc[i, 'arrival_time'] = dt.timedelta(
            hours=arr_time.hour, minutes=arr_time.minute, seconds=arr_time.second).total_seconds()
    # create dictionary for the first stop of each trip
    first_stop_dict.update({k: v for k, v in zip(
        data['trip_number'], data['start_stop'])})
    # create dictionary for the last stop of each trip
    last_stop_dict.update({k: v for k, v in zip(
        data['trip_number'], data['last_stop'])})
    # create departure and arrival times dictionary
    dep_time_dict.update({i: j for i, j in zip(
        data['trip_number'], data['departure_time'])})
    arr_time_dict.update({i: j for i, j in zip(
        data['trip_number'], data['arrival_time'])})
    # calculate travel time for each trip
    for k1, v1 in dep_time_dict.items():
        for k2, v2 in arr_time_dict.items():
            if k1 == k2:
                travel_time = v2 - v1
                travel_time_dict.update({k1: travel_time})
    # list of trips on the same line
    line_trips_dict.update({k: list(v) for k, v in data.groupby(
        'system_linenr')['trip_number']})
    # list of trips operating by the same bus
    bus_trips_dict.update({k: list(v)
                           for k, v in data.groupby('vehicle_number')['trip_number']})

    # return datasets
    return first_stop_dict, last_stop_dict, dep_time_dict, arr_time_dict, travel_time_dict


def calculate_waiting_time(date):

    waiting_time_dict = {}

    cursor, conn = connect_to_database()
    data = pd.read_sql(
        "SELECT * FROM timetable WHERE operating_date = '{}'".format(date), conn)
    cursor.close()

    # convert time to seconds
    for i in range(len(data)):
        dep_time = data.loc[i, 'departure_time']
        data.loc[i, 'departure_time'] = dt.timedelta(
            hours=dep_time.hour, minutes=dep_time.minute, seconds=dep_time.second).total_seconds()
    for i in range(len(data)):
        pass_time = data.loc[i, 'passing_time']
        data.loc[i, 'passing_time'] = dt.timedelta(
            hours=pass_time.hour, minutes=pass_time.minute, seconds=pass_time.second).total_seconds()

    for i in range(len(data)):
        data.loc[i, 'hour'] = int(data.loc[i, 'passing_time']/3600)

    data = data.sort_values(by=['system_linenr', 'direction', 'passing_time'])

    # calculate headway for different time of the day: peak and off-peak
    data['headway'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'passing_time'].transform(pd.Series.diff)
    data.dropna(inplace=True)

    data['variance'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'headway'].transform(statistics.variance)
    data['mean'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'headway'].transform(statistics.mean)

    def cal_waiting_time(mean, var):
        waiting_time = mean * 0.5 + 0.5 * (var / mean)
        return waiting_time
    # calculate waiting time
    data['waiting_time'] = cal_waiting_time(
        data['mean'], data['variance'])

    waiting_time_dict.update({(i, j): k for i, j, k in zip(
        data['trip_number'], data['stop'], data['waiting_time'])})

    return waiting_time_dict


def calculate_distance(lat1, lon1, lat2, lon2):

    distance = gmaps.distance_matrix([str(lat1) + " " + str(lon1)],
                                     [str(lat2) + " " + str(lon2)],
                                     departure_time=datetime.now().timestamp(),
                                     mode='driving')["rows"][0]["elements"][0]["duration"]["value"]
    return distance


def calculate_deadhead(date):
    cursor, conn = connect_to_database()
    date= str(date)
    data = pd.read_sql(
        "SELECT * FROM timetable WHERE operating_date = '{}'".format(date), conn)
    data = data.replace({np.nan: None})

    for i in range(len(data)):
        if data.loc[i, 'passing_time'] is not None:
            data.loc[i, 'passing_time'] = data.loc[i, 'passing_time']
        else:
            data.loc[i, 'passing_time'] = data.loc[i, 'arrival_time']
    first_stop = data.sort_values(by=['trip_number', 'passing_time']).drop_duplicates(
        subset=['trip_number'], keep='first')

    # create dictionary for the last stop of each trip
    last_stop = data.sort_values(by=['trip_number', 'passing_time']).drop_duplicates(
        subset=['trip_number'], keep='last')

    stops = pd.read_csv(
        r'C:/Users/FARAHMANDZH/OneDrive - University of Twente/Documenten/PDEng Project/Data/bus_stops.csv', sep=';')
    cursor.close()

    first_stop = pd.merge(first_stop, stops, left_on=[
                          'stop'], right_on=['IdDimHalte'])
    last_stop = pd.merge(last_stop, stops, left_on=[
        'stop'], right_on=['IdDimHalte'])

    first_stop.drop_duplicates('stop', inplace=True, keep='first')

    last_stop.drop_duplicates('stop', inplace=True, keep='first')
    first_stop_dict = {}
    last_stop_dict = {}
    first_stop_dict.update({i: (j, v) for i, j, v in zip(
        first_stop['stop'],  first_stop['Breedtegraad'], first_stop['Lengtegraad'])})
    # create dictionary for the last stop of each trip
    last_stop_dict.update({i: (j, v) for i, j, v in zip(
        last_stop['stop'], last_stop['Breedtegraad'], last_stop['Lengtegraad'])})

    data = pd.DataFrame(columns=['stopA', 'stopB', 'deadhead'])
    for key1, val1 in first_stop_dict.items():
        for key2, val2 in first_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)
    for key1, val1 in first_stop_dict.items():
        for key2, val2 in last_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)
    for key1, val1 in last_stop_dict.items():
        for key2, val2 in first_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)

    data.drop_duplicates(subset=['stopA', 'stopB'], inplace=True, keep='first')
    # directly store the data to the databse
    data = data.values.tolist()
    cursor, conn = connect_to_database()
    sql_insert = '''
        declare @stopA bigint = ?
        declare @stopB bigint = ?
        declare @deadhead float = ?

        UPDATE deadhead_time    
        SET deadhead = @deadhead
        WHERE stopA = @stopA AND stopB = @stopB

        IF @@ROWCOUNT = 0
            INSERT INTO deadhead_time
                (stopA, stopB, deadhead)
            VALUES (@stopA, @stopB, @deadhead)
        '''
    cursor.executemany(sql_insert, data)

    conn.commit()

date = dt.datetime.today().date() + timedelta(days=1)
calculate_deadhead(date)

```

pylint crashed with a ``MemoryError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1111, in _check_files
    self._check_file(get_ast, check_astroid_module, file)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1146, in _check_file
    check_astroid_module(ast_node)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1298, in check_astroid_module
    retval = self._check_astroid_module(
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1345, in _check_astroid_module
    walker.walk(node)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 76, in walk
    self.walk(child)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 73, in walk
    callback(astroid)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\checkers\variables.py", line 1722, in visit_import
    module = next(_infer_name_module(node, parts[0]))
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 136, in raise_if_nothing_inferred
    yield next(generator)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\inference.py", line 266, in infer_import
    yield self.do_import_module(name)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\mixins.py", line 102, in do_import_module
    return mymodule.import_module(
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(absmodname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 189, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 102, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 133, in file_build
    module, builder = self._data_build(data, modname, path)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 168, in _data_build
    node, parser_module = _parse_string(data, type_comments=True)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 454, in _parse_string
    parsed = parser_module.parse(data + "\n", type_comments=type_comments)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\_ast.py", line 49, in parse
    return parse_func(string)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\ast.py", line 50, in parse
    return compile(source, filename, mode, flags,
MemoryError
```

Issue title:
Crash ``[Errno 22] Invalid argument`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
from math import comb
import statistics
import datetime as dt
from datetime import datetime, timedelta

from traceback import format_exception
from unittest.util import sorted_list_difference
from webbrowser import get
from click import secho
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from gurobipy import tuplelist
import googlemaps
from soupsieve import select
import pyodbc
from matplotlib import style
plt.style.use('seaborn-dark')

# Requires API key
gmaps = googlemaps.Client(key='AIzaSyAUksLuaZra4mCcOLZL_52b9nIvHa7TgFw')
# gmaps = googlemaps.Client(key='AIzaSyAra0o3L3rs-uHn4EpaXx1Y57SIF_02684')


def connect_to_database():
    conn = pyodbc.connect('Driver={SQL Server Native Client 11.0};'
                          'Server=UT163156;'
                          'Database=keolis;'
                          'Trusted_Connection=yes;')
    cursor = conn.cursor()
    return cursor, conn




def import_data(date):
    # call data from the database
    cursor, conn = connect_to_database()
    data = pd.read_sql_query(
        "select * from pred_occupancy_per_stop where operating_date = '{}' ".format(date), conn)
    cursor.close()

    data['departure_time'] = pd.to_datetime(
        data['departure_time'], format='%Y-%m-%d %H:%M:%S')
    data['passing_time'] = pd.to_datetime(
        data['passing_time'], format='%Y-%m-%d %H:%M:%S')

    data.sort_values(by=['dep_time', 'system_linenr',
                     'direction', 'trip_number'], inplace=True)
    return data


def preliminary_parameters(date):
    cursor, conn = connect_to_database()
    data = pd.read_sql(
        "SELECT * FROM trips_timetable WHERE operating_date = '{}'".format(date), conn)
    cursor.close()

    first_stop_dict = {}
    last_stop_dict = {}
    bus_trips_dict = {}
    line_trips_dict = {}
    dep_time_dict = {}
    arr_time_dict = {}
    travel_time_dict = {}
    # convert time to seconds
    for i in range(len(data)):
        dep_time = data.loc[i, 'departure_time']
        data.loc[i, 'departure_time'] = dt.timedelta(
            hours=dep_time.hour, minutes=dep_time.minute, seconds=dep_time.second).total_seconds()
    for i in range(len(data)):
        arr_time = data.loc[i, 'arrival_time']
        data.loc[i, 'arrival_time'] = dt.timedelta(
            hours=arr_time.hour, minutes=arr_time.minute, seconds=arr_time.second).total_seconds()
    # create dictionary for the first stop of each trip
    first_stop_dict.update({k: v for k, v in zip(
        data['trip_number'], data['start_stop'])})
    # create dictionary for the last stop of each trip
    last_stop_dict.update({k: v for k, v in zip(
        data['trip_number'], data['last_stop'])})
    # create departure and arrival times dictionary
    dep_time_dict.update({i: j for i, j in zip(
        data['trip_number'], data['departure_time'])})
    arr_time_dict.update({i: j for i, j in zip(
        data['trip_number'], data['arrival_time'])})
    # calculate travel time for each trip
    for k1, v1 in dep_time_dict.items():
        for k2, v2 in arr_time_dict.items():
            if k1 == k2:
                travel_time = v2 - v1
                travel_time_dict.update({k1: travel_time})
    # list of trips on the same line
    line_trips_dict.update({k: list(v) for k, v in data.groupby(
        'system_linenr')['trip_number']})
    # list of trips operating by the same bus
    bus_trips_dict.update({k: list(v)
                           for k, v in data.groupby('vehicle_number')['trip_number']})

    # return datasets
    return first_stop_dict, last_stop_dict, dep_time_dict, arr_time_dict, travel_time_dict


def calculate_waiting_time(date):

    waiting_time_dict = {}

    cursor, conn = connect_to_database()
    data = pd.read_sql(
        "SELECT * FROM timetable WHERE operating_date = '{}'".format(date), conn)
    cursor.close()

    # convert time to seconds
    for i in range(len(data)):
        dep_time = data.loc[i, 'departure_time']
        data.loc[i, 'departure_time'] = dt.timedelta(
            hours=dep_time.hour, minutes=dep_time.minute, seconds=dep_time.second).total_seconds()
    for i in range(len(data)):
        pass_time = data.loc[i, 'passing_time']
        data.loc[i, 'passing_time'] = dt.timedelta(
            hours=pass_time.hour, minutes=pass_time.minute, seconds=pass_time.second).total_seconds()

    for i in range(len(data)):
        data.loc[i, 'hour'] = int(data.loc[i, 'passing_time']/3600)

    data = data.sort_values(by=['system_linenr', 'direction', 'passing_time'])

    # calculate headway for different time of the day: peak and off-peak
    data['headway'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'passing_time'].transform(pd.Series.diff)
    data.dropna(inplace=True)

    data['variance'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'headway'].transform(statistics.variance)
    data['mean'] = data.groupby(by=['system_linenr', 'direction', 'stop'])[
        'headway'].transform(statistics.mean)

    def cal_waiting_time(mean, var):
        waiting_time = mean * 0.5 + 0.5 * (var / mean)
        return waiting_time
    # calculate waiting time
    data['waiting_time'] = cal_waiting_time(
        data['mean'], data['variance'])

    waiting_time_dict.update({(i, j): k for i, j, k in zip(
        data['trip_number'], data['stop'], data['waiting_time'])})

    return waiting_time_dict


def calculate_distance(lat1, lon1, lat2, lon2):

    distance = gmaps.distance_matrix([str(lat1) + " " + str(lon1)],
                                     [str(lat2) + " " + str(lon2)],
                                     departure_time=datetime.now().timestamp(),
                                     mode='driving')["rows"][0]["elements"][0]["duration"]["value"]
    return distance


def calculate_deadhead(date):
    cursor, conn = connect_to_database()
    date= str(date)
    data = pd.read_sql(
        "SELECT * FROM timetable WHERE operating_date = '{}'".format(date), conn)
    data = data.replace({np.nan: None})

    for i in range(len(data)):
        if data.loc[i, 'passing_time'] is not None:
            data.loc[i, 'passing_time'] = data.loc[i, 'passing_time']
        else:
            data.loc[i, 'passing_time'] = data.loc[i, 'arrival_time']
    first_stop = data.sort_values(by=['trip_number', 'passing_time']).drop_duplicates(
        subset=['trip_number'], keep='first')

    # create dictionary for the last stop of each trip
    last_stop = data.sort_values(by=['trip_number', 'passing_time']).drop_duplicates(
        subset=['trip_number'], keep='last')

    stops = pd.read_csv(
        r'C:/Users/FARAHMANDZH/OneDrive - University of Twente/Documenten/PDEng Project/Data/bus_stops.csv', sep=';')
    cursor.close()

    first_stop = pd.merge(first_stop, stops, left_on=[
                          'stop'], right_on=['IdDimHalte'])
    last_stop = pd.merge(last_stop, stops, left_on=[
        'stop'], right_on=['IdDimHalte'])

    first_stop.drop_duplicates('stop', inplace=True, keep='first')

    last_stop.drop_duplicates('stop', inplace=True, keep='first')
    first_stop_dict = {}
    last_stop_dict = {}
    first_stop_dict.update({i: (j, v) for i, j, v in zip(
        first_stop['stop'],  first_stop['Breedtegraad'], first_stop['Lengtegraad'])})
    # create dictionary for the last stop of each trip
    last_stop_dict.update({i: (j, v) for i, j, v in zip(
        last_stop['stop'], last_stop['Breedtegraad'], last_stop['Lengtegraad'])})

    data = pd.DataFrame(columns=['stopA', 'stopB', 'deadhead'])
    for key1, val1 in first_stop_dict.items():
        for key2, val2 in first_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)
    for key1, val1 in first_stop_dict.items():
        for key2, val2 in last_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)
    for key1, val1 in last_stop_dict.items():
        for key2, val2 in first_stop_dict.items():
            if key1 != key2:
                data = data.append({'stopA': key1, 'stopB': key2, 'deadhead': calculate_distance(
                    val1[0], val1[1], val2[0], val2[1])}, ignore_index=True)
            elif key1 == key2:
                data = data.append(
                    {'stopA': key1, 'stopB': key2, 'deadhead': 0}, ignore_index=True)

    data.drop_duplicates(subset=['stopA', 'stopB'], inplace=True, keep='first')
    # directly store the data to the databse
    data = data.values.tolist()
    cursor, conn = connect_to_database()
    sql_insert = '''
        declare @stopA bigint = ?
        declare @stopB bigint = ?
        declare @deadhead float = ?

        UPDATE deadhead_time    
        SET deadhead = @deadhead
        WHERE stopA = @stopA AND stopB = @stopB

        IF @@ROWCOUNT = 0
            INSERT INTO deadhead_time
                (stopA, stopB, deadhead)
            VALUES (@stopA, @stopB, @deadhead)
        '''
    cursor.executemany(sql_insert, data)

    conn.commit()

date = dt.datetime.today().date() + timedelta(days=1)
calculate_deadhead(date)

```

pylint crashed with a ``OSError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 35, in cached
    return cache[func]
KeyError: <bound method ClassDef.slots of <ClassDef.datetime l.1563 at 0x1bcbf548c10>>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 73, in walk
    callback(astroid)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\checkers\variables.py", line 1722, in visit_import
    module = next(_infer_name_module(node, parts[0]))
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 136, in raise_if_nothing_inferred
    yield next(generator)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\inference.py", line 266, in infer_import
    yield self.do_import_module(name)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\mixins.py", line 102, in do_import_module
    return mymodule.import_module(
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(absmodname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 189, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 102, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 134, in file_build
    return self._post_build(module, builder, encoding)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 156, in _post_build
    self.delayed_assattr(delayed)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 234, in delayed_assattr
    if not _can_assign_attr(inferred, node.attrname):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 46, in _can_assign_attr
    slots = node.slots()
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 37, in cached
    cache[func] = result = func(*args, **kwargs)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 3010, in slots
    slots = list(grouped_slots(mro))
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 2990, in grouped_slots
    cls_slots = cls._slots()
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 2964, in _slots
    first = next(slots)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 2907, in _islots
    for slots in self.igetattr("__slots__"):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 2676, in igetattr
    for inferred in bases._infer_stmts(attributes, context, frame=self):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\bases.py", line 134, in _infer_stmts
    for inf in stmt.infer(context=context):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 136, in raise_if_nothing_inferred
    yield next(generator)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\bases.py", line 134, in _infer_stmts
    for inf in stmt.infer(context=context):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 123, in yes_if_nothing_inferred
    yield next(generator)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\inference.py", line 481, in _filter_operation_errors
    for result in infer_callable(self, context):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\inference.py", line 773, in _infer_binop
    for lhs, rhs in itertools.product(lhs_iter, rhs_iter):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 146, in raise_if_nothing_inferred
    yield from generator
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\inference.py", line 308, in infer_attribute
    for owner in self.expr.infer(context):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 146, in raise_if_nothing_inferred
    yield from generator
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\bases.py", line 134, in _infer_stmts
    for inf in stmt.infer(context=context):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 136, in raise_if_nothing_inferred
    yield next(generator)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\bases.py", line 134, in _infer_stmts
    for inf in stmt.infer(context=context):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\node_ng.py", line 182, in infer
    for i, result in enumerate(generator):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 136, in raise_if_nothing_inferred
    yield next(generator)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\decorators.py", line 105, in wrapped
    for res in _func(node, context, **kwargs):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\inference.py", line 288, in infer_import_from
    module = self.do_import_module()
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\mixins.py", line 102, in do_import_module
    return mymodule.import_module(
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\nodes\scoped_nodes\scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(absmodname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 189, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\manager.py", line 102, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 133, in file_build
    module, builder = self._data_build(data, modname, path)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 168, in _data_build
    node, parser_module = _parse_string(data, type_comments=True)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\builder.py", line 454, in _parse_string
    parsed = parser_module.parse(data + "\n", type_comments=type_comments)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\astroid\_ast.py", line 49, in parse
    return parse_func(string)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\ast.py", line 50, in parse
    return compile(source, filename, mode, flags,
SystemError: <built-in function compile> returned NULL without setting an exception

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 76, in walk
    self.walk(child)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 83, in walk
    traceback.print_exc()
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\traceback.py", line 179, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\traceback.py", line 121, in print_exception
    print(line, file=file, end="")
OSError: [Errno 22] Invalid argument

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1111, in _check_files
    self._check_file(get_ast, check_astroid_module, file)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1146, in _check_file
    check_astroid_module(ast_node)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1298, in check_astroid_module
    retval = self._check_astroid_module(
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\lint\pylinter.py", line 1345, in _check_astroid_module
    walker.walk(node)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\site-packages\pylint\utils\ast_walker.py", line 83, in walk
    traceback.print_exc()
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\traceback.py", line 179, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "C:\Users\FarahmandZH\Anaconda3\envs\keolis\lib\traceback.py", line 121, in print_exception
    print(line, file=file, end="")
OSError: [Errno 22] Invalid argument
```
